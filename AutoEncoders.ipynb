{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f86cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d9659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2997144",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d08ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                   1                             2\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy\n",
       "...    ...                                 ...                           ...\n",
       "3878  3948             Meet the Parents (2000)                        Comedy\n",
       "3879  3949          Requiem for a Dream (2000)                         Drama\n",
       "3880  3950                    Tigerland (2000)                         Drama\n",
       "3881  3951             Two Family House (2000)                         Drama\n",
       "3882  3952               Contender, The (2000)                Drama|Thriller\n",
       "\n",
       "[3883 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb72e538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1   2   3      4\n",
       "0        1  F   1  10  48067\n",
       "1        2  M  56  16  70072\n",
       "2        3  M  25  15  55117\n",
       "3        4  M  45   7  02460\n",
       "4        5  M  25  20  55455\n",
       "...    ... ..  ..  ..    ...\n",
       "6035  6036  F  25  15  32603\n",
       "6036  6037  F  45   1  76006\n",
       "6037  6038  F  56   1  14706\n",
       "6038  6039  F  45   0  01060\n",
       "6039  6040  M  25   6  11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e22f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1  2          3\n",
       "0           1  1193  5  978300760\n",
       "1           1   661  3  978302109\n",
       "2           1   914  3  978301968\n",
       "3           1  3408  4  978300275\n",
       "4           1  2355  5  978824291\n",
       "...       ...   ... ..        ...\n",
       "1000204  6040  1091  1  956716541\n",
       "1000205  6040  1094  5  956704887\n",
       "1000206  6040   562  5  956704746\n",
       "1000207  6040  1096  4  956715648\n",
       "1000208  6040  1097  4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f459241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1   1.1  5  874965758\n",
      "0        1     2  3  876893171\n",
      "1        1     3  4  878542960\n",
      "2        1     4  3  876893119\n",
      "3        1     5  3  889751712\n",
      "4        1     7  4  875071561\n",
      "...    ...   ... ..        ...\n",
      "79994  943  1067  2  875501756\n",
      "79995  943  1074  4  888640250\n",
      "79996  943  1188  3  888640250\n",
      "79997  943  1228  3  888640275\n",
      "79998  943  1330  3  888692465\n",
      "\n",
      "[79999 rows x 4 columns]\n",
      "         1     6  5  887431973\n",
      "0        1    10  3  875693118\n",
      "1        1    12  5  878542960\n",
      "2        1    14  5  874965706\n",
      "3        1    17  3  875073198\n",
      "4        1    20  4  887431883\n",
      "...    ...   ... ..        ...\n",
      "19994  458   648  4  886395899\n",
      "19995  458  1101  4  886397931\n",
      "19996  459   934  3  879563639\n",
      "19997  460    10  3  882912371\n",
      "19998  462   682  5  886365231\n",
      "\n",
      "[19999 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "print(training_set)\n",
    "training_set = np.array(training_set, dtype = 'int')  # converting the dataframe into a numpy array\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "print(test_set)\n",
    "test_set = np.array(test_set, dtype = 'int')  # converting the dataframe into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ec170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total number of users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb148aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3046aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users:  943\n",
      "Total movies:  1682\n"
     ]
    }
   ],
   "source": [
    "print(\"Total users: \",nb_users)\n",
    "print(\"Total movies: \",nb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into a matrix with 'users' in rows and 'movies' in columns (usual structure for any deep learning model)\n",
    "# We will create a list of list containing 943 lists of users where each list contains the ratings of 1682 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5737a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users+1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users]  # extracts all the movie ids of the current user\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_users] # extracts all the ratings of the current user\n",
    "        ratings = np.zeros(nb_movies)  # initialising a list of 1682 0s\n",
    "        ratings[id_movies - 1] = id_ratings  # list belonging to current user gets updated by ratings of movies which are rated by the current user. Movies which are not rated by current user are rated as 0.\n",
    "        new_data.append(list(ratings))  # adding the list belonging to single user to the list of list. This way 943 lists get added to list of list\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3bd6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)  \n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abaf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the architecture of the Neural Network (Stacked AutoEncoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c12ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):  # Here nn.Module is the base class for neural networks. We are creating a subclass SAE that extends this nn.Module class\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()   # To get all the inherited classes and methods of nn module class\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)  # Full connection between input layer and 1st hidden layer created using Linear class of nn module. No.of neurons in each hidden layer can be taken anything (Refer PyTorch Documentation for further details)\n",
    "        self.fc2 = nn.Linear(20, 10)  # Full connection between 1st hidden layer and 2nd hidden layer\n",
    "        self.fc3 = nn.Linear(10, 20)  # Full connection between 2nd hidden layer and 3rd hidden layer\n",
    "        self.fc4 = nn.Linear(20, nb_movies)  # Full connection between 3rd hidden layer and output layer (output layer has same dimension as input layer in AutoEncoders)\n",
    "        self.activation = nn.Sigmoid()   # Taking the activation func as 'sigmoid'. Here we use 'Sigmoid' class of nn module.\n",
    "    def forward(self, x):   # method for performing operations inside the SAE, i.e. to perform encoding and decoding (Forward Propagation)\n",
    "        x = self.activation(self.fc1(x))  # 1st encoding for 1st full connection\n",
    "        x = self.activation(self.fc2(x))  # 2nd encoding for 2nd full connection\n",
    "        x = self.activation(self.fc3(x))  # 1st decoding for 3rd full connection\n",
    "        x = self.fc4(x)   # 2nd (Final) decoding for 4th full connection\n",
    "        return x    # Now 'x' becomes the vector of predicted ratings\n",
    "    \n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()  # defining the loss function (Mean squared Error) using MSELoss class of nn module\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)   # defining the Optimizer using RMSprop class of optim module\n",
    "# weight_decay is used to reduce the lr after every few epochs. This improves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75087c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4140892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 1.772211365108864\n",
      "epoch: 2 train_loss: 1.096502091451791\n",
      "epoch: 3 train_loss: 1.0535028838367548\n",
      "epoch: 4 train_loss: 1.0383157640212335\n",
      "epoch: 5 train_loss: 1.0308870318950867\n",
      "epoch: 6 train_loss: 1.0267459663600502\n",
      "epoch: 7 train_loss: 1.0237340680991933\n",
      "epoch: 8 train_loss: 1.0218786398369761\n",
      "epoch: 9 train_loss: 1.0206072603270961\n",
      "epoch: 10 train_loss: 1.0198187932755418\n",
      "epoch: 11 train_loss: 1.0187255985057282\n",
      "epoch: 12 train_loss: 1.018535845761225\n",
      "epoch: 13 train_loss: 1.017964634409972\n",
      "epoch: 14 train_loss: 1.0175357420590194\n",
      "epoch: 15 train_loss: 1.017005529882621\n",
      "epoch: 16 train_loss: 1.01705321570111\n",
      "epoch: 17 train_loss: 1.0166847821610583\n",
      "epoch: 18 train_loss: 1.016551206606653\n",
      "epoch: 19 train_loss: 1.0159693468004354\n",
      "epoch: 20 train_loss: 1.016239082294117\n",
      "epoch: 21 train_loss: 1.015988103532113\n",
      "epoch: 22 train_loss: 1.015824577331143\n",
      "epoch: 23 train_loss: 1.0157990025342651\n",
      "epoch: 24 train_loss: 1.0157604455752274\n",
      "epoch: 25 train_loss: 1.0158624523228885\n",
      "epoch: 26 train_loss: 1.0154704320179935\n",
      "epoch: 27 train_loss: 1.015131857378731\n",
      "epoch: 28 train_loss: 1.0147762387707417\n",
      "epoch: 29 train_loss: 1.0128243574154725\n",
      "epoch: 30 train_loss: 1.0114030756276373\n",
      "epoch: 31 train_loss: 1.008846825840851\n",
      "epoch: 32 train_loss: 1.0064775570090438\n",
      "epoch: 33 train_loss: 1.0044666934740165\n",
      "epoch: 34 train_loss: 1.002479406040097\n",
      "epoch: 35 train_loss: 1.0022048554012735\n",
      "epoch: 36 train_loss: 0.9984560213656065\n",
      "epoch: 37 train_loss: 0.9976454512131612\n",
      "epoch: 38 train_loss: 0.9940798809404497\n",
      "epoch: 39 train_loss: 0.9939306876068423\n",
      "epoch: 40 train_loss: 0.989424970915653\n",
      "epoch: 41 train_loss: 0.9885867279789383\n",
      "epoch: 42 train_loss: 0.9879265229367509\n",
      "epoch: 43 train_loss: 0.983442280347633\n",
      "epoch: 44 train_loss: 0.9822809562629996\n",
      "epoch: 45 train_loss: 0.9837708012769365\n",
      "epoch: 46 train_loss: 0.9841777078006043\n",
      "epoch: 47 train_loss: 0.9853668463532893\n",
      "epoch: 48 train_loss: 0.98149776421117\n",
      "epoch: 49 train_loss: 0.982539084784937\n",
      "epoch: 50 train_loss: 0.9796373536214306\n",
      "epoch: 51 train_loss: 0.9835798760625905\n",
      "epoch: 52 train_loss: 0.9847022054963668\n",
      "epoch: 53 train_loss: 0.9830122980377205\n",
      "epoch: 54 train_loss: 0.9804550772355811\n",
      "epoch: 55 train_loss: 0.980375520541544\n",
      "epoch: 56 train_loss: 0.9790871979992601\n",
      "epoch: 57 train_loss: 0.9745223807075833\n",
      "epoch: 58 train_loss: 0.9789190246722103\n",
      "epoch: 59 train_loss: 0.9746869384343236\n",
      "epoch: 60 train_loss: 0.9739766572494052\n",
      "epoch: 61 train_loss: 0.9721023028824947\n",
      "epoch: 62 train_loss: 0.9676377629237075\n",
      "epoch: 63 train_loss: 0.9672503209481381\n",
      "epoch: 64 train_loss: 0.9616771984374239\n",
      "epoch: 65 train_loss: 0.9637975751011664\n",
      "epoch: 66 train_loss: 0.9594479774683355\n",
      "epoch: 67 train_loss: 0.9573828020305815\n",
      "epoch: 68 train_loss: 0.9583788758763384\n",
      "epoch: 69 train_loss: 0.9599733977095616\n",
      "epoch: 70 train_loss: 0.9588006600038377\n",
      "epoch: 71 train_loss: 0.957537668762384\n",
      "epoch: 72 train_loss: 0.9547309177223013\n",
      "epoch: 73 train_loss: 0.953843071651415\n",
      "epoch: 74 train_loss: 0.95281889861896\n",
      "epoch: 75 train_loss: 0.9525770063954038\n",
      "epoch: 76 train_loss: 0.9499358847879925\n",
      "epoch: 77 train_loss: 0.9499787599656212\n",
      "epoch: 78 train_loss: 0.948455170548665\n",
      "epoch: 79 train_loss: 0.9477560186057313\n",
      "epoch: 80 train_loss: 0.9461657498411029\n",
      "epoch: 81 train_loss: 0.9458993310315699\n",
      "epoch: 82 train_loss: 0.9452038254749625\n",
      "epoch: 83 train_loss: 0.9476192352989512\n",
      "epoch: 84 train_loss: 0.9461102971732394\n",
      "epoch: 85 train_loss: 0.9442765936302575\n",
      "epoch: 86 train_loss: 0.9433013718387965\n",
      "epoch: 87 train_loss: 0.9426340060489796\n",
      "epoch: 88 train_loss: 0.9412020765803137\n",
      "epoch: 89 train_loss: 0.9423929232652685\n",
      "epoch: 90 train_loss: 0.9410100025386834\n",
      "epoch: 91 train_loss: 0.9411549111194945\n",
      "epoch: 92 train_loss: 0.9410739050233035\n",
      "epoch: 93 train_loss: 0.9414710194333763\n",
      "epoch: 94 train_loss: 0.9392957605247445\n",
      "epoch: 95 train_loss: 0.9402370118940931\n",
      "epoch: 96 train_loss: 0.9382224710853341\n",
      "epoch: 97 train_loss: 0.9382825053981868\n",
      "epoch: 98 train_loss: 0.9368328994109927\n",
      "epoch: 99 train_loss: 0.9376351694428988\n",
      "epoch: 100 train_loss: 0.9369018350179825\n",
      "epoch: 101 train_loss: 0.9373090367911371\n",
      "epoch: 102 train_loss: 0.936430260301779\n",
      "epoch: 103 train_loss: 0.9363551368994627\n",
      "epoch: 104 train_loss: 0.9352721585283882\n",
      "epoch: 105 train_loss: 0.9352431615006209\n",
      "epoch: 106 train_loss: 0.934782661157112\n",
      "epoch: 107 train_loss: 0.9343151974471573\n",
      "epoch: 108 train_loss: 0.9342385532532111\n",
      "epoch: 109 train_loss: 0.9346836617194748\n",
      "epoch: 110 train_loss: 0.9341010509187208\n",
      "epoch: 111 train_loss: 0.9330708920279795\n",
      "epoch: 112 train_loss: 0.9327877707526695\n",
      "epoch: 113 train_loss: 0.9324199292264564\n",
      "epoch: 114 train_loss: 0.9322498298916205\n",
      "epoch: 115 train_loss: 0.9311361730527911\n",
      "epoch: 116 train_loss: 0.9313354950781378\n",
      "epoch: 117 train_loss: 0.9307297658037249\n",
      "epoch: 118 train_loss: 0.9305559252081923\n",
      "epoch: 119 train_loss: 0.9313816065841113\n",
      "epoch: 120 train_loss: 0.9304852808499182\n",
      "epoch: 121 train_loss: 0.9297099735645077\n",
      "epoch: 122 train_loss: 0.9294837096160836\n",
      "epoch: 123 train_loss: 0.9293827522019559\n",
      "epoch: 124 train_loss: 0.9289813363641418\n",
      "epoch: 125 train_loss: 0.9287429592828881\n",
      "epoch: 126 train_loss: 0.9281994289918973\n",
      "epoch: 127 train_loss: 0.9281911373435534\n",
      "epoch: 128 train_loss: 0.9278588867424431\n",
      "epoch: 129 train_loss: 0.92794874658268\n",
      "epoch: 130 train_loss: 0.9272258436753823\n",
      "epoch: 131 train_loss: 0.9272943815310205\n",
      "epoch: 132 train_loss: 0.9261602172491082\n",
      "epoch: 133 train_loss: 0.9261344303575814\n",
      "epoch: 134 train_loss: 0.925992139011911\n",
      "epoch: 135 train_loss: 0.9258834178968588\n",
      "epoch: 136 train_loss: 0.9254218319282748\n",
      "epoch: 137 train_loss: 0.9253211220807821\n",
      "epoch: 138 train_loss: 0.924693680306188\n",
      "epoch: 139 train_loss: 0.9248677885754207\n",
      "epoch: 140 train_loss: 0.9243312057418158\n",
      "epoch: 141 train_loss: 0.9238786423947484\n",
      "epoch: 142 train_loss: 0.9236769047537747\n",
      "epoch: 143 train_loss: 0.9236302785473085\n",
      "epoch: 144 train_loss: 0.9230156064435969\n",
      "epoch: 145 train_loss: 0.9232295128887219\n",
      "epoch: 146 train_loss: 0.9226160948906831\n",
      "epoch: 147 train_loss: 0.9227976237136646\n",
      "epoch: 148 train_loss: 0.9219861641341379\n",
      "epoch: 149 train_loss: 0.9222529351971022\n",
      "epoch: 150 train_loss: 0.9216121633188831\n",
      "epoch: 151 train_loss: 0.9217096706595074\n",
      "epoch: 152 train_loss: 0.921298956590392\n",
      "epoch: 153 train_loss: 0.924983796330109\n",
      "epoch: 154 train_loss: 0.9207599778014532\n",
      "epoch: 155 train_loss: 0.921085180249756\n",
      "epoch: 156 train_loss: 0.9205597399596179\n",
      "epoch: 157 train_loss: 0.920692749633125\n",
      "epoch: 158 train_loss: 0.9198796672829472\n",
      "epoch: 159 train_loss: 0.920278185981669\n",
      "epoch: 160 train_loss: 0.9193309866722214\n",
      "epoch: 161 train_loss: 0.9194355045825661\n",
      "epoch: 162 train_loss: 0.9193212643300592\n",
      "epoch: 163 train_loss: 0.9193807988454914\n",
      "epoch: 164 train_loss: 0.9187868181877704\n",
      "epoch: 165 train_loss: 0.9189147741617381\n",
      "epoch: 166 train_loss: 0.9183679409805486\n",
      "epoch: 167 train_loss: 0.9186805923026664\n",
      "epoch: 168 train_loss: 0.9178892641013263\n",
      "epoch: 169 train_loss: 0.9182949314804499\n",
      "epoch: 170 train_loss: 0.9175855544078353\n",
      "epoch: 171 train_loss: 0.9177962382732661\n",
      "epoch: 172 train_loss: 0.9172400709740871\n",
      "epoch: 173 train_loss: 0.9175792382541336\n",
      "epoch: 174 train_loss: 0.917202399619314\n",
      "epoch: 175 train_loss: 0.917127601347049\n",
      "epoch: 176 train_loss: 0.9168083979893253\n",
      "epoch: 177 train_loss: 0.9169075271768246\n",
      "epoch: 178 train_loss: 0.9161496203298642\n",
      "epoch: 179 train_loss: 0.9164036219203932\n",
      "epoch: 180 train_loss: 0.9161332501046301\n",
      "epoch: 181 train_loss: 0.9161046865430613\n",
      "epoch: 182 train_loss: 0.915685928700702\n",
      "epoch: 183 train_loss: 0.9159047149312145\n",
      "epoch: 184 train_loss: 0.9157801786127434\n",
      "epoch: 185 train_loss: 0.9157517301914654\n",
      "epoch: 186 train_loss: 0.915335407976955\n",
      "epoch: 187 train_loss: 0.91558304750228\n",
      "epoch: 188 train_loss: 0.9151835270351351\n",
      "epoch: 189 train_loss: 0.9151840248677069\n",
      "epoch: 190 train_loss: 0.9147563851915783\n",
      "epoch: 191 train_loss: 0.9143409137685753\n",
      "epoch: 192 train_loss: 0.9145467832129613\n",
      "epoch: 193 train_loss: 0.914682095169641\n",
      "epoch: 194 train_loss: 0.9145540505745979\n",
      "epoch: 195 train_loss: 0.9143146896411037\n",
      "epoch: 196 train_loss: 0.9143080741907891\n",
      "epoch: 197 train_loss: 0.9138517872537244\n",
      "epoch: 198 train_loss: 0.9137551324893681\n",
      "epoch: 199 train_loss: 0.9138621883273413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200 train_loss: 0.9139163664651386\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)  # adding a second dimension (second dimension is of batch)to the input as PyTorch cannot take single dimension (just like keras)\n",
    "        target = input.clone()  # creating a backup variable for input vector\n",
    "        if torch.sum(target.data > 0) > 0:   # considering those users who have rated atleast 1 movie\n",
    "            output = sae.forward(input)  # calling the forward() to get the predicted ratings\n",
    "            target.require_grad = False  # for optimizing the code to reduce a lot of computations by not calculating the gradient\n",
    "            output[target == 0] = 0   # The ratings which are originally 0 (not rated by a user) are taken as 0 in final output\n",
    "            loss = criterion(output, target)  # calculating the loss by comparing the predicted ratings and actual ratings\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()  # Performing Backpropagation for adjusting the weights. Determines whether we need to increase the weights or decrease the weights\n",
    "            train_loss += np.sqrt(loss.item() * mean_corrector) # calculating the Root Mean Square Error (RMSE)\n",
    "            s += 1.\n",
    "            optimizer.step()  # To apply the optimizer of RMSprop class we use inbuilt step() of the class\n",
    "            # backwards() decides whether weights are to be increased or decreased whereas optimizers decides by how much amount the weights are to be adjusted\n",
    "    print('epoch: '+str(epoch)+' train_loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c1c84b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.9496858995110379\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)  # adding a second dimension (second dimension is of batch)to the input as PyTorch cannot take single dimension (just like keras)\n",
    "    # here we take training set and not test set because we want to predict the ratings of the movies that the user has not watched in the training set and then compare these predicted ratings with the actual ratings of those movies that are present in the test set.\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)  # target contains the actual ratings of the movies in the test set that were not watched by the users in the training set\n",
    "    if torch.sum(target.data > 0) > 0:   # considering those users who have rated atleast 1 movie\n",
    "        output = sae.forward(input)  # calling the forward() to get the predicted ratings\n",
    "        target.require_grad = False  # for optimizing the code to reduce a lot of computations by not calculating the gradient\n",
    "        output[target == 0] = 0   # The ratings which are originally 0 (not rated by a user) are taken as 0 in final output\n",
    "        loss = criterion(output, target)  # calculating the loss by comparing the predicted ratings and actual ratings\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.item() * mean_corrector) # calculating the Root Mean Square Error (RMSE)\n",
    "        s += 1.\n",
    "print('test_loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions for a given user and for a given movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03d50be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating: 3.6260068\n"
     ]
    }
   ],
   "source": [
    "user_id = 3\n",
    "movie_id = 482\n",
    "input = Variable(training_set[user_id-1]).unsqueeze(0)\n",
    "predicted_rating = sae.forward(input)\n",
    "predicted_rating = predicted_rating.data.numpy()\n",
    "print('Predicted Rating: '+ str(predicted_rating[0, movie_id-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b097e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
